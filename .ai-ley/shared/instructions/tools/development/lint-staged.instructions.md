---
agentMode: general
applyTo:
  - '**/package.json'
  - '**/.lintstagedrc*'
  - '**/lint-staged.config.*'
  - '**/.husky/**'
  - '**/.*ignore'
author: AI-LEY
category: Development Tools
description: Enterprise-grade Lint-staged platform with advanced pre-commit validation automation, comprehensive security scanning integration, intelligent policy enforcement, sophisticated file processing engines, enterprise workflow optimization, and advanced developer productivity analytics for complete enterprise pre-commit security and quality assurance operations.
extensions:
  - .md
guidelines: N/A
instructionType: general
keywords: []
lastUpdated: '2025-09-03T00:04:47.926431'
last_updated: '2025-08-14'
summaryScore: 3.0
tags:
  - lint-staged
  - pre-commit
  - linting
  - formatting
  - git-hooks
  - husky
  - performance
  - code-quality
  - enterprise-security
  - validation-automation
  - policy-enforcement
  - workflow-optimization
  - security-scanning
  - compliance-validation
  - productivity-analytics
title: Lint-staged Enterprise Pre-commit Security & Quality Validation Platform
version: '2.0'
---

# Lint-staged Enterprise Pre-commit Security & Quality Validation Platform

## Enterprise Platform Overview

- **Platform Name**: Lint-staged Enterprise Validation Engine
- **Version**: 2.0+ (Advanced enterprise platform with comprehensive security automation)
- **Category**: Enterprise Pre-commit Security & Quality Validation
- **Core Purpose**: Advanced pre-commit validation automation, security scanning integration, policy enforcement, intelligent file processing, and comprehensive enterprise workflow optimization
- **Enterprise Capabilities**: Security validation, compliance enforcement, threat detection, automated remediation, workflow analytics, performance optimization
- **Prerequisites**: Enterprise development environment, Git hooks system, Node.js 18+, advanced security toolchain integration

# === Enterprise Lint-staged Security & Validation Framework ===

import logging
import json
import yaml
import os
import re
import subprocess
import hashlib
import sqlite3
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Union, Callable
from pathlib import Path
from dataclasses import dataclass, field
from enum import Enum
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp

logger = logging.getLogger(**name**)

class ValidationSeverity(Enum):
"""Validation severity levels for pre-commit processing"""
CRITICAL = "CRITICAL"
HIGH = "HIGH"
MEDIUM = "MEDIUM"
LOW = "LOW"
INFO = "INFO"

class FileProcessingStrategy(Enum):
"""File processing strategies for enterprise validation"""
PARALLEL_BATCH = "parallel_batch"
SEQUENTIAL = "sequential"
INTELLIGENT_PRIORITY = "intelligent_priority"
SECURITY_FIRST = "security_first"
PERFORMANCE_OPTIMIZED = "performance_optimized"

class ComplianceFramework(Enum):
"""Compliance frameworks for file validation"""
OWASP = "OWASP"
PCI_DSS = "PCI-DSS"
HIPAA = "HIPAA"
GDPR = "GDPR"
ISO_27001 = "ISO-27001"
SOX = "SOX"
NIST_CYBERSECURITY = "NIST-Cybersecurity"

@dataclass
class EnterpriseRepository:
"""Enterprise repository configuration"""
repo_id: str
name: str
path: Path
security_level: str
compliance_requirements: List[ComplianceFramework]
file_types: List[str]
business_criticality: str = "medium"
data_sensitivity: str = "internal"
team_size: int = 5

@dataclass
class FileValidationRule:
"""Enterprise file validation rule definition"""
rule_id: str
name: str
description: str
severity: ValidationSeverity
file_patterns: List[str]
validation_commands: List[str]
security_checks: List[str]
compliance_frameworks: List[ComplianceFramework]
remediation_actions: List[str]
performance_impact: str = "low"

@dataclass
class ValidationResult:
"""Result of file validation process"""
file_path: str
validation_timestamp: datetime
overall_status: str
security_score: float
quality_score: float
compliance_score: float
violations: List[Dict[str, Any]]
security_issues: List[Dict[str, Any]]
performance_metrics: Dict[str, Any]

class EnterpriseLintStagedEngine:
"""Advanced enterprise lint-staged validation and security engine"""

    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or self._load_default_enterprise_config()
        self.validation_engine = self._initialize_validation_engine()
        self.security_scanner = self._initialize_security_scanner()
        self.compliance_validator = self._initialize_compliance_validator()
        self.performance_optimizer = self._initialize_performance_optimizer()
        self.analytics_engine = self._initialize_analytics_engine()
        self.db_connection = self._initialize_database()
        logger.info("Enterprise Lint-staged Engine initialized")

    def _load_default_enterprise_config(self) -> Dict[str, Any]:
        """Load comprehensive enterprise validation configuration"""
        return {
            "security_validation": {
                "secret_scanning": True,
                "vulnerability_detection": True,
                "malware_scanning": True,
                "license_compliance": True,
                "dependency_security": True,
                "code_injection_detection": True
            },
            "quality_validation": {
                "syntax_validation": True,
                "code_complexity_analysis": True,
                "test_coverage_validation": True,
                "documentation_validation": True,
                "performance_analysis": True,
                "maintainability_checks": True
            },
            "compliance_validation": {
                "regulatory_compliance": True,
                "coding_standards": True,
                "security_standards": True,
                "audit_trail_generation": True,
                "evidence_collection": True
            },
            "performance_optimization": {
                "parallel_processing": True,
                "intelligent_caching": True,
                "incremental_validation": True,
                "resource_optimization": True,
                "load_balancing": True
            },
            "enterprise_integrations": {
                "security_tools": ["SonarQube", "Veracode", "Checkmarx", "Snyk"],
                "quality_tools": ["ESLint", "Prettier", "TSLint", "Pylint"],
                "compliance_tools": ["OWASP-ZAP", "Bandit", "Safety", "Semgrep"],
                "monitoring_systems": ["DataDog", "New-Relic", "Splunk"]
            }
        }

    def setup_enterprise_lint_staged_config(self, repository: EnterpriseRepository) -> Dict[str, Any]:
        """Setup comprehensive enterprise lint-staged configuration"""
        logger.info(f"Setting up enterprise lint-staged configuration for {repository.name}")

        config_result = {
            "repository_id": repository.repo_id,
            "setup_timestamp": datetime.now().isoformat(),
            "validation_rules": [],
            "security_scanners": [],
            "compliance_checks": [],
            "performance_optimizations": {},
            "workflow_automation": {}
        }

        try:
            # Generate security-focused validation rules
            security_rules = self._generate_security_validation_rules(repository)
            config_result["validation_rules"].extend(security_rules)

            # Generate quality validation rules
            quality_rules = self._generate_quality_validation_rules(repository)
            config_result["validation_rules"].extend(quality_rules)

            # Generate compliance validation rules
            compliance_rules = self._generate_compliance_validation_rules(repository)
            config_result["validation_rules"].extend(compliance_rules)

            # Configure security scanners
            security_scanners = self._configure_security_scanners(repository)
            config_result["security_scanners"] = security_scanners

            # Configure performance optimizations
            performance_config = self._configure_performance_optimizations(repository)
            config_result["performance_optimizations"] = performance_config

            # Generate lint-staged configuration file
            lint_staged_config = self._generate_lint_staged_config_file(repository, config_result)
            config_result["config_file_content"] = lint_staged_config

            # Write configuration to file
            config_file_path = repository.path / ".lintstagedrc.js"
            with open(config_file_path, 'w') as f:
                f.write(lint_staged_config)

            config_result["config_file_path"] = str(config_file_path)

            logger.info(f"Enterprise lint-staged configuration created with {len(config_result['validation_rules'])} rules")

        except Exception as e:
            logger.error(f"Enterprise lint-staged configuration setup failed: {e}")
            config_result["error"] = str(e)

        return config_result

    def _generate_security_validation_rules(self, repository: EnterpriseRepository) -> List[FileValidationRule]:
        """Generate security-focused validation rules"""
        security_rules = []

        # Secret scanning rule
        secret_rule = FileValidationRule(
            rule_id="SEC_001",
            name="Secret Detection and Validation",
            description="Detect and prevent secrets from being committed",
            severity=ValidationSeverity.CRITICAL,
            file_patterns=["**/*.js", "**/*.ts", "**/*.py", "**/*.java", "**/*.cs", "**/*.php", "**/*.rb"],
            validation_commands=[
                "truffleHog --json --entropy=False git://.",
                "detect-secrets scan --baseline .secrets.baseline",
                "gitleaks detect --source=."
            ],
            security_checks=[
                "api_key_detection", "password_detection", "token_detection",
                "private_key_detection", "certificate_detection"
            ],
            compliance_frameworks=[ComplianceFramework.PCI_DSS, ComplianceFramework.HIPAA, ComplianceFramework.SOX],
            remediation_actions=["mask_secrets", "move_to_env", "add_to_gitignore"],
            performance_impact="medium"
        )
        security_rules.append(secret_rule)

        # Vulnerability scanning rule
        vuln_rule = FileValidationRule(
            rule_id="SEC_002",
            name="Dependency Vulnerability Scanning",
            description="Scan dependencies for known security vulnerabilities",
            severity=ValidationSeverity.HIGH,
            file_patterns=["**/package.json", "**/requirements.txt", "**/Gemfile", "**/pom.xml"],
            validation_commands=[
                "npm audit --audit-level=moderate",
                "safety check --json",
                "snyk test --json"
            ],
            security_checks=["cve_detection", "license_compliance", "dependency_analysis"],
            compliance_frameworks=[ComplianceFramework.OWASP, ComplianceFramework.NIST_CYBERSECURITY],
            remediation_actions=["update_dependencies", "apply_patches", "find_alternatives"],
            performance_impact="high"
        )
        security_rules.append(vuln_rule)

        # Code injection detection rule
        injection_rule = FileValidationRule(
            rule_id="SEC_003",
            name="Code Injection Pattern Detection",
            description="Detect patterns that could lead to code injection vulnerabilities",
            severity=ValidationSeverity.HIGH,
            file_patterns=["**/*.js", "**/*.ts", "**/*.py", "**/*.php", "**/*.java"],
            validation_commands=[
                "semgrep --config=security --json",
                "bandit -f json",
                "eslint --ext .js,.ts --format json"
            ],
            security_checks=[
                "sql_injection_patterns", "xss_patterns", "command_injection_patterns",
                "ldap_injection_patterns", "xpath_injection_patterns"
            ],
            compliance_frameworks=[ComplianceFramework.OWASP, ComplianceFramework.PCI_DSS],
            remediation_actions=["sanitize_inputs", "use_parameterized_queries", "validate_inputs"],
            performance_impact="medium"
        )
        security_rules.append(injection_rule)

        # Malware scanning rule (for high-security environments)
        if repository.security_level in ["high", "critical"]:
            malware_rule = FileValidationRule(
                rule_id="SEC_004",
                name="Malware and Suspicious Content Detection",
                description="Scan files for malware signatures and suspicious patterns",
                severity=ValidationSeverity.CRITICAL,
                file_patterns=["**/*"],
                validation_commands=[
                    "clamav-scan --json",
                    "yara-scan --json"
                ],
                security_checks=["malware_signatures", "suspicious_patterns", "file_entropy_analysis"],
                compliance_frameworks=[ComplianceFramework.ISO_27001, ComplianceFramework.NIST_CYBERSECURITY],
                remediation_actions=["quarantine_file", "security_team_alert", "block_commit"],
                performance_impact="high"
            )
            security_rules.append(malware_rule)

        return security_rules

    def execute_enterprise_validation(self, repository: EnterpriseRepository, staged_files: List[str]) -> Dict[str, Any]:
        """Execute comprehensive enterprise validation on staged files"""
        logger.info(f"Starting enterprise validation for {len(staged_files)} staged files")

        validation_result = {
            "repository_id": repository.repo_id,
            "validation_start": datetime.now().isoformat(),
            "files_processed": 0,
            "files_passed": 0,
            "files_failed": 0,
            "security_issues_found": 0,
            "compliance_violations": 0,
            "file_results": [],
            "overall_status": "PASS",
            "performance_metrics": {}
        }

        try:
            # Determine optimal processing strategy
            processing_strategy = self._determine_processing_strategy(repository, staged_files)

            # Execute validation based on strategy
            if processing_strategy == FileProcessingStrategy.PARALLEL_BATCH:
                file_results = self._execute_parallel_validation(repository, staged_files)
            elif processing_strategy == FileProcessingStrategy.INTELLIGENT_PRIORITY:
                file_results = self._execute_intelligent_priority_validation(repository, staged_files)
            elif processing_strategy == FileProcessingStrategy.SECURITY_FIRST:
                file_results = self._execute_security_first_validation(repository, staged_files)
            else:
                file_results = self._execute_sequential_validation(repository, staged_files)

            validation_result["file_results"] = file_results
            validation_result["files_processed"] = len(file_results)

            # Analyze results
            for result in file_results:
                if result["overall_status"] == "PASS":
                    validation_result["files_passed"] += 1
                else:
                    validation_result["files_failed"] += 1

                validation_result["security_issues_found"] += len(result.get("security_issues", []))
                validation_result["compliance_violations"] += len([v for v in result.get("violations", []) if v.get("type") == "compliance"])

            # Determine overall validation status
            if validation_result["files_failed"] > 0 or validation_result["security_issues_found"] > 0:
                validation_result["overall_status"] = "FAIL"

            # Generate performance metrics
            validation_result["performance_metrics"] = self._calculate_validation_performance_metrics(validation_result)

            # Generate remediation recommendations
            validation_result["remediation_recommendations"] = self._generate_remediation_recommendations(validation_result)

            validation_result["validation_end"] = datetime.now().isoformat()

            # Store validation results
            self._store_validation_results(repository, validation_result)

            logger.info(f"Enterprise validation completed: {validation_result['overall_status']} - {validation_result['files_passed']}/{validation_result['files_processed']} files passed")

        except Exception as e:
            logger.error(f"Enterprise validation failed: {e}")
            validation_result["error"] = str(e)
            validation_result["overall_status"] = "ERROR"

        return validation_result

    def _execute_parallel_validation(self, repository: EnterpriseRepository, staged_files: List[str]) -> List[Dict[str, Any]]:
        """Execute parallel file validation for optimal performance"""

        file_results = []
        max_workers = min(mp.cpu_count(), len(staged_files), 8)  # Limit to reasonable number

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # Submit validation tasks
            future_to_file = {
                executor.submit(self._validate_single_file, repository, file_path): file_path
                for file_path in staged_files
            }

            # Collect results as they complete
            for future in future_to_file:
                file_path = future_to_file[future]
                try:
                    result = future.result(timeout=120)  # 2 minute timeout per file
                    file_results.append(result)
                except Exception as e:
                    logger.error(f"Validation failed for {file_path}: {e}")
                    file_results.append({
                        "file_path": file_path,
                        "overall_status": "ERROR",
                        "error": str(e),
                        "security_score": 0.0,
                        "quality_score": 0.0,
                        "compliance_score": 0.0
                    })

        return file_results

    def _validate_single_file(self, repository: EnterpriseRepository, file_path: str) -> Dict[str, Any]:
        """Validate a single file with comprehensive security and quality checks"""

        file_result = {
            "file_path": file_path,
            "validation_timestamp": datetime.now().isoformat(),
            "overall_status": "PASS",
            "security_score": 10.0,
            "quality_score": 10.0,
            "compliance_score": 10.0,
            "violations": [],
            "security_issues": [],
            "performance_metrics": {}
        }

        validation_start = datetime.now()

        try:
            file_full_path = repository.path / file_path

            # Read file content for analysis
            with open(file_full_path, 'r', encoding='utf-8', errors='ignore') as f:
                file_content = f.read()

            # 1. Security Validation
            security_result = self._perform_file_security_validation(file_path, file_content, repository)
            file_result["security_score"] = security_result["security_score"]
            file_result["security_issues"].extend(security_result.get("security_issues", []))

            # 2. Quality Validation
            quality_result = self._perform_file_quality_validation(file_path, file_content, repository)
            file_result["quality_score"] = quality_result["quality_score"]
            file_result["violations"].extend(quality_result.get("violations", []))

            # 3. Compliance Validation
            compliance_result = self._perform_file_compliance_validation(file_path, file_content, repository)
            file_result["compliance_score"] = compliance_result["compliance_score"]
            file_result["violations"].extend(compliance_result.get("violations", []))

            # 4. Determine overall status
            min_score = min(file_result["security_score"], file_result["quality_score"], file_result["compliance_score"])
            if min_score < 7.0 or len(file_result["security_issues"]) > 0:
                file_result["overall_status"] = "FAIL"

            # 5. Calculate performance metrics
            validation_duration = (datetime.now() - validation_start).total_seconds()
            file_result["performance_metrics"] = {
                "validation_duration": validation_duration,
                "file_size": os.path.getsize(file_full_path) if os.path.exists(file_full_path) else 0,
                "lines_analyzed": len(file_content.splitlines())
            }

        except Exception as e:
            logger.error(f"File validation failed for {file_path}: {e}")
            file_result["overall_status"] = "ERROR"
            file_result["error"] = str(e)

        return file_result

    def _perform_file_security_validation(self, file_path: str, file_content: str, repository: EnterpriseRepository) -> Dict[str, Any]:
        """Perform comprehensive security validation on a single file"""

        security_result = {
            "security_score": 10.0,
            "security_issues": [],
            "patterns_detected": []
        }

        # Secret detection patterns
        secret_patterns = [
            (r'(?i)password\s*=\s*["\'][^"\']+["\']', "password_hardcoded"),
            (r'(?i)api[_-]?key\s*=\s*["\'][^"\']+["\']', "api_key_hardcoded"),
            (r'(?i)secret\s*=\s*["\'][^"\']+["\']', "secret_hardcoded"),
            (r'(?i)token\s*=\s*["\'][^"\']+["\']', "token_hardcoded"),
            (r'-----BEGIN [A-Z ]+-----', "private_key_detected"),
            (r'(?i)aws[_-]?access[_-]?key', "aws_credentials"),
            (r'(?i)postgres://[^\\s]+', "database_url"),
        ]

        for pattern, issue_type in secret_patterns:
            matches = re.finditer(pattern, file_content)
            for match in matches:
                security_result["security_issues"].append({
                    "type": issue_type,
                    "severity": "CRITICAL",
                    "line": file_content[:match.start()].count('\n') + 1,
                    "message": f"Potential secret detected: {issue_type}",
                    "match": match.group(0)[:50] + "..." if len(match.group(0)) > 50 else match.group(0)
                })
                security_result["security_score"] -= 2.0

        # Code injection patterns
        injection_patterns = [
            (r'(?i)eval\s*\(', "eval_usage"),
            (r'(?i)exec\s*\(', "exec_usage"),
            (r'(?i)system\s*\(', "system_call"),
            (r'(?i)shell_exec\s*\(', "shell_exec"),
            (r'document\.write\s*\(', "document_write"),
            (r'innerHTML\s*=.*\+', "innerHTML_concatenation"),
            (r'SELECT\s+.*\s+FROM\s+.*\s+WHERE\s+.*=.*\+', "sql_injection_risk"),
        ]

        for pattern, issue_type in injection_patterns:
            matches = re.finditer(pattern, file_content)
            for match in matches:
                security_result["security_issues"].append({
                    "type": issue_type,
                    "severity": "HIGH",
                    "line": file_content[:match.start()].count('\n') + 1,
                    "message": f"Potential security vulnerability: {issue_type}",
                    "match": match.group(0)
                })
                security_result["security_score"] -= 1.5

        # Ensure security score doesn't go below 0
        security_result["security_score"] = max(0.0, security_result["security_score"])

        return security_result

## When to Use Lint-staged

### ‚úÖ **Use Lint-staged When**

- Working with projects that have linting and formatting tools (ESLint, Prettier, etc.)
- Need to optimize pre-commit hook performance by processing only changed files
- Want to ensure code quality without slowing down development workflow
- Working in team environments requiring consistent code formatting standards
- Integrating multiple code quality tools that should run on specific file types
- Using pre-commit hooks and want to avoid processing entire codebase repeatedly
- Need conditional tool execution based on file types and patterns
- Want to prevent linting issues from being committed to repository

### ‚ùå **Avoid Lint-staged When**

- Project has no linting or formatting tools configured
- Working with very small codebases where full project linting is fast enough
- Need to run tools that require full project context (some type checkers)
- Working with monorepos where file relationships make selective processing problematic
- Using tools that don't support file-specific execution
- Team prefers post-commit or CI-only quality checks

## AI Agent Decision Matrix

### Project Type Assessment

| Project Type           | Lint-staged Recommendation                       | Configuration Priority           |
| ---------------------- | ------------------------------------------------ | -------------------------------- |
| Large Codebase         | ‚úÖ **Essential** - Major performance benefit     | High - Full tool integration     |
| Team Development       | ‚úÖ **Essential** - Consistent quality gates      | High - Comprehensive linting     |
| Open Source Project    | ‚úÖ **Recommended** - Contributor experience      | Medium - Standard patterns       |
| Monorepo               | üîÑ **Consider** - Complex file dependencies      | Medium - Selective configuration |
| Small Personal Project | üîÑ **Consider** - May be overkill                | Low - Basic formatting only      |
| Legacy Codebase        | ‚úÖ **Recommended** - Gradual quality improvement | Medium - Incremental adoption    |

### Performance Impact Assessment

| Factor                  | Low Impact           | Medium Impact                 | High Impact                   |
| ----------------------- | -------------------- | ----------------------------- | ----------------------------- |
| **Codebase Size**       | <1k files            | 1k-10k files                  | 10k+ files                    |
| **Tool Count**          | 1-2 tools (Prettier) | 3-4 tools (ESLint + Prettier) | 5+ tools (Full quality stack) |
| **File Types**          | Single language      | 2-3 languages                 | Multiple languages            |
| **Hook Execution Time** | <5 seconds savings   | 5-30 seconds savings          | 30+ seconds savings           |

## Installation & Setup

### Package Manager Installation

```bash
# npm installation (recommended for most projects)
npm install lint-staged --save-dev

# yarn installation
yarn add lint-staged --dev

# pnpm installation
pnpm add lint-staged --save-dev

# Global installation (for CLI usage)
npm install -g lint-staged

# Verify installation
npx lint-staged --version
```

### Project Integration with Husky

```bash
# Install Husky and lint-staged together
npm install husky lint-staged --save-dev

# Initialize Husky
npx husky init

# Create pre-commit hook with lint-staged
echo "npx lint-staged" > .husky/pre-commit
chmod +x .husky/pre-commit

# Test the setup
git add .
git commit -m "test: verify lint-staged setup"
```

### Manual Hook Integration

```bash
# Create .git/hooks/pre-commit manually
cat > .git/hooks/pre-commit << 'EOF'
#!/bin/sh
npx lint-staged
EOF

chmod +x .git/hooks/pre-commit

# Alternative: using git config
git config core.hooksPath .githooks
mkdir .githooks
echo "npx lint-staged" > .githooks/pre-commit
chmod +x .githooks/pre-commit
```

## Configuration

### Package.json Configuration

```json
{
  "lint-staged": {
    "*.{js,jsx,ts,tsx}": ["eslint --fix", "prettier --write"],
    "*.{css,scss,less}": ["stylelint --fix", "prettier --write"],
    "*.{json,md,yaml,yml}": ["prettier --write"],
    "*.{png,jpg,jpeg,gif,svg}": ["imagemin-lint-staged"]
  },
  "scripts": {
    "lint-staged": "lint-staged",
    "precommit": "lint-staged"
  },
  "devDependencies": {
    "lint-staged": "^15.0.0",
    "husky": "^9.0.0",
    "eslint": "^8.0.0",
    "prettier": "^3.0.0"
  }
}
```

### Dedicated Configuration File (.lintstagedrc.json)

```json
{
  "*.{js,jsx,ts,tsx}": ["eslint --fix", "prettier --write", "git add"],
  "*.{css,scss,less,styl}": ["stylelint --fix", "prettier --write", "git add"],
  "*.{json,md,mdx,yaml,yml}": ["prettier --write", "git add"],
  "*.{js,jsx,ts,tsx}": ["jest --bail --findRelatedTests --passWithNoTests"],
  "package.json": ["npm audit fix", "sort-package-json", "git add"]
}
```

### JavaScript Configuration (lint-staged.config.js)

```javascript
module.exports = {
  // JavaScript/TypeScript files
  '*.{js,jsx,ts,tsx}': [
    'eslint --fix',
    'prettier --write',
    // Run tests for related files
    'jest --bail --findRelatedTests --passWithNoTests',
  ],

  // Stylesheet files
  '*.{css,scss,less,styl}': ['stylelint --fix', 'prettier --write'],

  // Documentation and config files
  '*.{json,md,mdx,yaml,yml}': ['prettier --write'],

  // Python files (if using Python tools)
  '*.py': ['black', 'isort', 'flake8'],

  // Conditional processing based on file patterns
  '*.{png,jpg,jpeg,gif,svg}': (filenames) => {
    // Only run image optimization on files larger than 10KB
    return filenames
      .filter((filename) => {
        const stats = require('fs').statSync(filename);
        return stats.size > 10240; // 10KB
      })
      .map((filename) => `imagemin ${filename} --out-dir=optimized/`);
  },

  // Environment-specific configuration
  '*.{js,ts}':
    process.env.NODE_ENV === 'production'
      ? ['eslint --fix', 'prettier --write', 'npm run test:unit']
      : ['eslint --fix', 'prettier --write'],
};
```

### Advanced Configuration with Functions

```javascript
// lint-staged.config.js - Advanced configuration
const path = require('path');

module.exports = {
  // Dynamic command generation
  '*.{js,jsx,ts,tsx}': (filenames) => {
    const commands = [];

    // ESLint with specific config based on file location
    commands.push(
      filenames
        .map((filename) => {
          const isTestFile = filename.includes('.test.') || filename.includes('.spec.');
          const config = isTestFile ? '.eslintrc.test.js' : '.eslintrc.js';
          return `eslint --config ${config} --fix ${filename}`;
        })
        .join(' && '),
    );

    // Prettier formatting
    commands.push(`prettier --write ${filenames.join(' ')}`);

    // Type checking for TypeScript files
    const tsFiles = filenames.filter((file) => file.endsWith('.ts') || file.endsWith('.tsx'));
    if (tsFiles.length > 0) {
      commands.push('npx tsc --noEmit');
    }

    // Run related tests
    commands.push(`jest --bail --findRelatedTests ${filenames.join(' ')} --passWithNoTests`);

    return commands;
  },

  // CSS/SCSS with conditional Sass compilation
  '*.{css,scss}': (filenames) => {
    const commands = ['stylelint --fix', 'prettier --write'];

    const scssFiles = filenames.filter((file) => file.endsWith('.scss'));
    if (scssFiles.length > 0) {
      commands.push('npm run build:css');
    }

    return commands.concat(filenames.map((f) => `git add ${f}`));
  },

  // Package.json validation and sorting
  'package.json': ['npm audit fix --force', 'sort-package-json', 'prettier --write', 'git add'],

  // Documentation with link checking
  '*.md': ['markdownlint --fix', 'prettier --write', 'markdown-link-check'],
};
```

## Core Features

### Selective File Processing

- **Purpose**: Processes only Git staged files instead of entire project
- **Usage**: Automatically detects staged files and applies tools selectively
- **Example**:

```bash
# Only runs on staged files
git add src/component.js src/styles.css
npx lint-staged  # Only processes these 2 files

# Compared to full project processing
eslint src/         # Processes all files in src/
prettier --write src/**/*  # Processes all files
```

### Pattern-based Tool Execution

- **Purpose**: Runs different tools based on file patterns and extensions
- **Usage**: Configures specific tools for specific file types
- **Example**:

```json
{
  "*.js": ["eslint --fix"],
  "*.css": ["stylelint --fix"],
  "*.md": ["markdownlint --fix"],
  "*.{png,jpg}": ["imagemin-lint-staged"]
}
```

### Command Chaining and Conditional Execution

- **Purpose**: Executes multiple commands in sequence with failure handling
- **Usage**: Chains linting, formatting, and testing in optimal order
- **Example**:

```javascript
// Commands run in sequence, stop on first failure
'*.js': [
  'eslint --fix',        // Fix linting issues first
  'prettier --write',    // Format code
  'git add',             // Stage the fixed files
  'jest --findRelatedTests'  // Run related tests
]
```

### Dynamic Command Generation

- **Purpose**: Generates commands dynamically based on file content or conditions
- **Usage**: Advanced scenarios requiring conditional processing logic
- **Example**:

```javascript
'*.js': (filenames) => {
  const testFiles = filenames.filter(f => f.includes('.test.'));
  const sourceFiles = filenames.filter(f => !f.includes('.test.'));

  const commands = [];
  if (sourceFiles.length > 0) {
    commands.push(`eslint --fix ${sourceFiles.join(' ')}`);
  }
  if (testFiles.length > 0) {
    commands.push(`jest --bail ${testFiles.join(' ')}`);
  }

  return commands;
}
```

## Common Commands

```bash
# Essential daily commands
npx lint-staged                      # Run on staged files
npx lint-staged --debug              # Debug mode with verbose output
npx lint-staged --verbose            # Verbose output
npx lint-staged --dry-run            # Preview what would run

# Configuration and testing
npx lint-staged --config=.lintstagedrc.json  # Use specific config
npx lint-staged --allow-empty         # Allow execution with no staged files
npx lint-staged --no-stash            # Don't stash unstaged changes

# Advanced operations
npx lint-staged --shell               # Use shell for command execution
npx lint-staged --quiet               # Minimal output
npx lint-staged --concurrent false    # Disable concurrent execution

# Integration commands
git add file.js && npx lint-staged    # Manual staging and processing
husky add .husky/pre-commit "npx lint-staged"  # Husky integration
```

## Workflow Integration

### Development Workflow

1. **Setup**: Install lint-staged and configure file patterns with appropriate tools
2. **Development**: Make changes to files as usual during development
3. **Staging**: Use `git add` to stage files for commit
4. **Validation**: lint-staged automatically runs on commit, processing only staged files
5. **Commit**: If all checks pass, commit succeeds; otherwise, fix issues and retry

### Team Development Workflow

```bash
# Team setup workflow
npm install lint-staged husky eslint prettier --save-dev

# Configure lint-staged in package.json
cat > package.json << 'EOF'
{
  "lint-staged": {
    "*.{js,jsx,ts,tsx}": [
      "eslint --fix",
      "prettier --write"
    ],
    "*.{css,scss}": [
      "stylelint --fix",
      "prettier --write"
    ]
  }
}
EOF

# Set up pre-commit hook
npx husky init
echo "npx lint-staged" > .husky/pre-commit
chmod +x .husky/pre-commit

# Commit the configuration
git add .
git commit -m "feat: add lint-staged for code quality automation"
```

### CI/CD Integration

```yaml
# .github/workflows/quality.yml
name: Code Quality
on: [push, pull_request]

jobs:
  lint-staged-validation:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for proper diff

      - uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - run: npm ci

      # Simulate lint-staged behavior in CI
      - name: Get changed files
        id: changed-files
        run: |
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            echo "files=$(git diff --name-only ${{ github.event.pull_request.base.sha }} ${{ github.sha }} | tr '
' ' ')" >> $GITHUB_OUTPUT
          else
            echo "files=$(git diff --name-only HEAD~1 HEAD | tr '
' ' ')" >> $GITHUB_OUTPUT
          fi

      - name: Run lint-staged on changed files
        if: steps.changed-files.outputs.files != ''
        run: |
          # Set up staged files simulation
          echo "${{ steps.changed-files.outputs.files }}" | xargs git add
          npx lint-staged
```

### Monorepo Integration

```javascript
// lint-staged.config.js for monorepo
const path = require('path');

module.exports = {
  // Frontend package
  'packages/frontend/**/*.{js,jsx,ts,tsx}': [
    'eslint --config packages/frontend/.eslintrc.js --fix',
    'prettier --config packages/frontend/.prettierrc --write',
    'jest --config packages/frontend/jest.config.js --findRelatedTests',
  ],

  // Backend package
  'packages/backend/**/*.{js,ts}': [
    'eslint --config packages/backend/.eslintrc.js --fix',
    'prettier --config packages/backend/.prettierrc --write',
    'jest --config packages/backend/jest.config.js --findRelatedTests',
  ],

  // Shared utilities
  'packages/shared/**/*.{js,ts}': [
    'eslint --config packages/shared/.eslintrc.js --fix',
    'prettier --write',
    'npm run test:shared',
  ],

  // Root level configuration files
  'package.json': ['sort-package-json', 'prettier --write'],
  'packages/*/package.json': ['sort-package-json', 'prettier --write'],

  // Documentation
  '*.md': ['markdownlint --fix', 'prettier --write'],
  'docs/**/*.md': ['markdownlint --config docs/.markdownlint.json --fix'],
};
```

## Best Practices

### ‚úÖ **Configuration Best Practices**

- **Use specific file patterns** - Target exact file types to avoid unnecessary processing
- **Order commands logically** - Run linting before formatting, formatting before testing
- **Include git add carefully** - Only add files that tools have modified
- **Configure tool-specific settings** - Use project-specific configurations for each tool
- **Handle failures gracefully** - Ensure commands fail fast and provide clear error messages
- **Use concurrent execution** - Enable parallel processing for independent operations

### ‚úÖ **Performance Optimization**

- **Minimize tool overlap** - Avoid running multiple tools that perform similar functions
- **Use incremental tools** - Prefer tools that support file-specific operation modes
- **Leverage caching** - Configure tools to use caching when available
- **Optimize test selection** - Use --findRelatedTests to run only relevant tests
- **Group similar operations** - Batch similar file types together for efficiency
- **Profile execution time** - Monitor and optimize slow-running commands

### ‚úÖ **Team Collaboration**

- **Document configuration** - Include clear README instructions for setup
- **Standardize tool versions** - Lock tool versions in package.json for consistency
- **Provide bypass mechanisms** - Allow emergency commits with --no-verify when needed
- **Share configuration files** - Commit lint-staged config to ensure team alignment
- **Test hook setup** - Verify hooks work properly across different development environments
- **Handle editor integration** - Ensure lint-staged works with various IDEs and editors

### ‚ùå **Common Pitfalls to Avoid**

- **Don't run full project tests** - Use targeted testing to maintain performance benefits
- **Avoid git add in production** - Be careful with automatic staging in CI environments
- **Don't ignore tool exit codes** - Ensure lint-staged properly handles tool failures
- **Avoid conflicting tool configurations** - Ensure ESLint and Prettier configurations are compatible
- **Don't skip error handling** - Provide meaningful error messages for debugging
- **Avoid overly complex patterns** - Keep file patterns simple and maintainable

## Advanced Lint-staged Usage

### Conditional Processing Based on Environment

```javascript
// lint-staged.config.js - Environment-aware configuration
const isProduction = process.env.NODE_ENV === 'production';
const isCi = process.env.CI === 'true';

module.exports = {
  '*.{js,jsx,ts,tsx}': [
    'eslint --fix',
    'prettier --write',
    // Only run tests in non-CI environments
    ...(isCi ? [] : ['jest --bail --findRelatedTests --passWithNoTests']),
    // Only run type checking in production builds
    ...(isProduction ? ['tsc --noEmit'] : []),
  ],

  '*.{css,scss}': [
    'stylelint --fix',
    'prettier --write',
    // Only optimize CSS in production
    ...(isProduction ? ['postcss --use autoprefixer --replace'] : []),
  ],

  // Only run expensive operations in CI
  '*.{png,jpg,jpeg}': isCi
    ? ['imagemin-cli --plugin=imagemin-mozjpeg --plugin=imagemin-pngquant']
    : [],
};
```

### Custom Tool Integration

```javascript
// lint-staged.config.js - Custom tools and scripts
module.exports = {
  // Custom script for API documentation
  'src/api/**/*.js': [
    'eslint --fix',
    'prettier --write',
    'node scripts/generate-api-docs.js',
    'git add docs/api/',
  ],

  // Custom validation for configuration files
  '*.{json,yaml,yml}': (filenames) => {
    const commands = ['prettier --write'];

    filenames.forEach((filename) => {
      if (filename.endsWith('.json')) {
        commands.push(`node scripts/validate-json.js ${filename}`);
      }
      if (filename.includes('docker-compose')) {
        commands.push(`docker-compose -f ${filename} config`);
      }
    });

    return commands;
  },

  // Database migration validation
  'migrations/**/*.sql': ['node scripts/validate-migration.js', 'sql-formatter --fix'],

  // License header enforcement
  'src/**/*.{js,ts}': ['node scripts/add-license-header.js', 'eslint --fix', 'prettier --write'],
};
```

### Multi-stage Processing

```javascript
// lint-staged.config.js - Multi-stage processing pipeline
const { ESLint } = require('eslint');

module.exports = {
  // Stage 1: Fast checks (syntax, basic linting)
  '*.{js,jsx,ts,tsx}': async (filenames) => {
    const eslint = new ESLint({ fix: true });

    // Quick syntax check first
    const results = await eslint.lintFiles(filenames);
    const hasErrors = results.some((result) => result.errorCount > 0);

    if (hasErrors) {
      // If there are errors, only run basic fixes
      return ['eslint --fix --quiet', 'prettier --write'];
    } else {
      // If no errors, run full pipeline
      return [
        'eslint --fix',
        'prettier --write',
        'jest --bail --findRelatedTests --passWithNoTests',
        'npm run type-check',
      ];
    }
  },

  // Stage 2: Asset optimization (runs after main checks)
  '*.{png,jpg,jpeg,gif,svg}': ['imagemin-lint-staged', 'node scripts/update-asset-manifest.js'],
};
```

## Integration with Other Tools

### Husky Integration

```bash
# Complete Husky + lint-staged setup
npm install husky lint-staged --save-dev

# Initialize Husky
npx husky init

# Create pre-commit hook
cat > .husky/pre-commit << 'EOF'
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh"

# Run lint-staged
npx lint-staged

# Additional checks
npm run type-check
EOF

chmod +x .husky/pre-commit

# Create pre-push hook for comprehensive checks
cat > .husky/pre-push << 'EOF'
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh"

# Run full test suite before push
npm run test:coverage
npm run build
EOF

chmod +x .husky/pre-push
```

### ESLint and Prettier Integration

```json
// package.json - Coordinated tool configuration
{
  "lint-staged": {
    "*.{js,jsx,ts,tsx}": ["eslint --fix --max-warnings=0", "prettier --write", "git add"]
  },
  "eslintConfig": {
    "extends": ["eslint:recommended", "@typescript-eslint/recommended", "prettier"],
    "plugins": ["prettier"],
    "rules": {
      "prettier/prettier": "error"
    }
  },
  "prettier": {
    "semi": true,
    "singleQuote": true,
    "trailingComma": "es5",
    "tabWidth": 2
  }
}
```

### Jest Testing Integration

```javascript
// lint-staged.config.js - Advanced Jest integration
module.exports = {
  '*.{js,jsx,ts,tsx}': [
    'eslint --fix',
    'prettier --write',
    // Smart test execution
    (filenames) => {
      const testFiles = filenames.filter((f) => f.includes('.test.') || f.includes('.spec.'));
      const sourceFiles = filenames.filter((f) => !f.includes('.test.') && !f.includes('.spec.'));

      const commands = [];

      // Run test files directly
      if (testFiles.length > 0) {
        commands.push(`jest ${testFiles.join(' ')} --passWithNoTests`);
      }

      // Find and run tests related to source files
      if (sourceFiles.length > 0) {
        commands.push(`jest --findRelatedTests ${sourceFiles.join(' ')} --passWithNoTests`);
      }

      return commands;
    },
  ],
};
```

### Stylelint Integration

```json
{
  "lint-staged": {
    "*.{css,scss,less}": ["stylelint --fix", "prettier --write"]
  },
  "stylelint": {
    "extends": ["stylelint-config-standard", "stylelint-config-prettier"],
    "rules": {
      "property-no-unknown": true,
      "selector-class-pattern": "^[a-z][a-zA-Z0-9]*$"
    }
  }
}
```

## Troubleshooting

### Common Issues

#### Commands Not Running on Staged Files

**Problem**: lint-staged appears to run but doesn't process any files
**Symptoms**: No output or "No staged files found" message
**Solution**:

```bash
# Check if files are actually staged
git status --porcelain

# Stage files manually
git add file.js

# Check lint-staged configuration
npx lint-staged --debug

# Verify file patterns match staged files
npx lint-staged --dry-run --verbose
```

#### Tool Exit Code Issues

**Problem**: lint-staged fails with non-zero exit codes from tools
**Symptoms**: Pre-commit hook fails even when tools appear to run successfully
**Solution**:

```javascript
// Handle tools that return non-zero exit codes
module.exports = {
  '*.js': [
    'eslint --fix --max-warnings=0', // Fail on warnings
    'prettier --write --check', // Check formatting after write
  ],

  // Alternative: ignore exit codes for specific tools
  '*.css': 'stylelint --fix || true', // Continue even if stylelint fails
};
```

#### Performance Issues with Large Files

**Problem**: lint-staged takes too long on large codebases or files
**Symptoms**: Pre-commit hooks timeout or take several minutes
**Solution**:

```javascript
// Optimize for performance
module.exports = {
  '*.{js,ts}': [
    'eslint --fix --cache', // Use ESLint cache
    'prettier --write --cache', // Use Prettier cache
  ],

  // Skip large files
  '*.js': (filenames) => {
    const fs = require('fs');
    const smallFiles = filenames.filter((f) => {
      const stats = fs.statSync(f);
      return stats.size < 100000; // Skip files > 100KB
    });
    return `eslint --fix ${smallFiles.join(' ')}`;
  },
};
```

#### Git Add Issues

**Problem**: Modified files not being properly staged after tool modifications
**Symptoms**: Changes made by tools not included in commit
**Solution**:

```json
{
  "lint-staged": {
    "*.js": [
      "eslint --fix",
      "prettier --write",
      "git add" // Ensure modified files are staged
    ]
  }
}
```

### Debug Mode

```bash
# Enable comprehensive debugging
npx lint-staged --debug --verbose

# Check what commands would run
npx lint-staged --dry-run

# Test with specific files
git add specific-file.js
npx lint-staged --debug

# Verify configuration loading
npx lint-staged --help
npx lint-staged --print-config
```

### Performance Optimization

```javascript
// Optimized configuration for large projects
module.exports = {
  // Use concurrency for independent operations
  '*.{js,jsx,ts,tsx}': [
    'eslint --fix --cache --cache-location .eslintcache',
    'prettier --write --cache',
  ],

  // Separate CPU-intensive operations
  '*.{css,scss}': 'stylelint --fix --cache',

  // Group similar operations
  '*.{json,md,yaml}': 'prettier --write',

  // Use shell commands for complex operations
  'package*.json': 'sort-package-json && npm audit fix --force || true',

  // Conditional expensive operations
  '*.{png,jpg,jpeg}': (filenames) => {
    if (process.env.OPTIMIZE_IMAGES === 'true') {
      return `imagemin ${filenames.join(' ')} --out-dir=optimized/`;
    }
    return [];
  },
};
```

## Security Considerations

### Security Best Practices

- **Validate tool commands** - Ensure all tools and scripts used are trusted and validated
- **Limit file access** - Configure tools to only access necessary files and directories
- **Avoid shell injection** - Use array syntax instead of string concatenation for commands
- **Control tool execution** - Restrict which tools can be executed and their parameters
- **Audit dependencies** - Regularly audit lint-staged and tool dependencies for vulnerabilities
- **Secure configuration** - Protect configuration files from unauthorized modification

### Safe Command Execution

```javascript
// Secure command configuration
module.exports = {
  // Use array syntax to prevent shell injection
  '*.js': ['eslint --fix', 'prettier --write'],

  // Avoid dynamic command generation with user input
  // BAD: `eslint ${userInput}`
  // GOOD: predefined commands only

  // Validate file paths
  '*.js': (filenames) => {
    const safePaths = filenames.filter((f) => !f.includes('..') && f.startsWith('src/'));
    return [`eslint --fix ${safePaths.join(' ')}`];
  },
};
```

### Sensitive Data Protection

```javascript
// Prevent processing of sensitive files
module.exports = {
  // Exclude sensitive file patterns
  '*.{js,ts}': ['eslint --fix', 'prettier --write'],

  // Explicitly exclude sensitive patterns
  '!.env*': [],
  '!**/secrets/**': [],
  '!**/node_modules/**': [],

  // Validate against sensitive patterns
  '*': (filenames) => {
    const sensitivePatterns = ['.env', 'secret', 'password', 'key'];
    const hasSensitiveFiles = filenames.some((f) =>
      sensitivePatterns.some((pattern) => f.includes(pattern)),
    );

    if (hasSensitiveFiles) {
      throw new Error('Sensitive files detected in staging area');
    }

    return [];
  },
};
```

## AI Assistant Guidelines

When helping with lint-staged:

1. **Always suggest lint-staged 15.0+** for optimal performance and modern feature support
2. **Provide complete Husky integration** examples for seamless Git hook setup
3. **Include performance optimization** techniques for large codebases and teams
4. **Suggest tool-specific configurations** that work well together (ESLint + Prettier)
5. **Provide debugging strategies** for common setup and execution issues
6. **Include monorepo considerations** for complex project structures
7. **Reference security best practices** for safe command execution and file handling
8. **Suggest CI/CD integration patterns** that complement local lint-staged workflows

### Code Generation Rules

- Generate lint-staged configurations that use array syntax for security
- Include appropriate file patterns that match common project structures
- Provide error handling and fallback strategies for tool failures
- Include performance optimizations like caching and selective processing
- Follow conventional patterns for tool ordering (lint ‚Üí format ‚Üí test)
- Generate cross-platform compatible configurations and commands
- Include debugging and troubleshooting guidance for generated configurations
- Provide integration examples with popular development tools and workflows

## Installation & Setup

### Package Manager Installation

```bash
# npm/yarn installation
npm install -g [tool-name]
# or
yarn global add [tool-name]

# pip installation
pip install [tool-name]

# homebrew installation (macOS)
brew install [tool-name]

# Other platform-specific commands
[other installation methods]
```

### Project Integration

```bash
# Initialize in project
[tool] init

# Add to existing project
[project setup commands]
```

## Configuration

### Configuration File

```[config-format]
# [config-file-name] (e.g., .toolrc, tool.config.js, tool.yaml)
[configuration-example]
```

### Environment Variables

```bash
# Environment-specific settings
[TOOL_ENV_VAR]=[value]
[TOOL_CONFIG_PATH]=[path]
```

### CLI Configuration

```bash
# Global configuration
[tool] config set [option] [value]

# Project-specific configuration
[tool] config --local [option] [value]
```

## Core Features

### [Feature 1]

- **Purpose**: [What this feature does]
- **Usage**: [How to use it]
- **Example**:

```bash
[tool] [command] [options]
```

### [Feature 2]

- **Purpose**: [What this feature does]
- **Usage**: [How to use it]
- **Example**:

```bash
[tool] [command] [options]
```

### [Feature 3]

- **Purpose**: [What this feature does]
- **Usage**: [How to use it]
- **Example**:

```bash
[tool] [command] [options]
```

## Common Commands

```bash
# Essential daily commands
[tool] [basic-command]              # Description
[tool] [frequent-command] [options] # Description
[tool] [status-command]             # Check status
[tool] [help-command]               # Get help

# Advanced operations
[tool] [advanced-command] [options] # Description
[tool] [config-command]             # Configuration management
[tool] [debug-command]              # Debugging and troubleshooting
```

## Workflow Integration

### Development Workflow

1. **Setup**: [Initial setup steps]
2. **Development**: [How to use during development]
3. **Testing**: [Integration with testing process]
4. **Pre-commit**: [Pre-commit hooks or checks]
5. **CI/CD**: [Continuous integration usage]

### Automation Scripts

```bash
# Package.json scripts (if applicable)
{
  "scripts": {
    "[script-name]": "[tool] [command]",
    "[workflow-script]": "[tool] [workflow-command]"
  }
}
```

### Git Hooks Integration

```bash
# Pre-commit hook example
#!/bin/sh
[tool] [validation-command]
```

## Best Practices

### Configuration Best Practices

- [Best practice 1 with explanation]
- [Best practice 2 with explanation]
- [Best practice 3 with explanation]

### Usage Patterns

- [Pattern 1: When and how to use]
- [Pattern 2: When and how to use]
- [Pattern 3: When and how to use]

### Performance Optimization

- [Optimization tip 1]
- [Optimization tip 2]
- [Optimization tip 3]

## Common Use Cases

### [Use Case 1]

**Scenario**: [Description of the scenario]
**Implementation**:

```bash
[tool] [specific-commands]
```

**Expected Result**: [What should happen]

### [Use Case 2]

**Scenario**: [Description of the scenario]
**Implementation**:

```bash
[tool] [specific-commands]
```

**Expected Result**: [What should happen]

### [Use Case 3]

**Scenario**: [Description of the scenario]
**Implementation**:

```bash
[tool] [specific-commands]
```

**Expected Result**: [What should happen]

## Integration with Other Tools

### [Related Tool 1]

- **Integration Purpose**: [Why integrate]
- **Setup**: [How to configure integration]
- **Usage**: [How they work together]

### [Related Tool 2]

- **Integration Purpose**: [Why integrate]
- **Setup**: [How to configure integration]
- **Usage**: [How they work together]

## Troubleshooting

### Common Issues

#### [Issue 1]

**Problem**: [Description of the problem]
**Symptoms**: [How to identify this issue]
**Solution**: [Step-by-step fix]

#### [Issue 2]

**Problem**: [Description of the problem]
**Symptoms**: [How to identify this issue]
**Solution**: [Step-by-step fix]

#### [Issue 3]

**Problem**: [Description of the problem]
**Symptoms**: [How to identify this issue]
**Solution**: [Step-by-step fix]

### Debug Mode

```bash
# Enable verbose/debug output
[tool] --verbose [command]
[tool] --debug [command]

# Log analysis
[tool] logs
[tool] status --detailed
```

### Performance Issues

- [Performance issue 1 and solution]
- [Performance issue 2 and solution]
- [Performance issue 3 and solution]

## Security Considerations

### Security Best Practices

- [Security practice 1]
- [Security practice 2]
- [Security practice 3]

### Sensitive Data Handling

- [How the tool handles secrets]
- [Configuration for secure usage]
- [Best practices for credentials]

### Network Security

- [Network-related security considerations]
- [Proxy and firewall configurations]
- [Certificate and SSL handling]

## Advanced Configuration

### Custom Plugins/Extensions

```[config-format]
# Plugin configuration
[plugin-config-example]
```

### Scripting and Automation

```bash
# Advanced scripting examples
[automation-script-example]
```

### Performance Tuning

```[config-format]
# Performance optimization settings
[performance-config-example]
```

## Version Management

### Version Compatibility

- **Tool Version**: [Version requirements]
- **Node.js**: [If applicable]
- **Python**: [If applicable]
- **OS Support**: [Supported operating systems]

### Migration Guides

- **From [Old Version]**: [Migration steps]
- **Breaking Changes**: [Important changes to note]
- **Deprecation Notices**: [Features being deprecated]

## Useful Resources

- **Official Documentation**: [URL]
- **GitHub Repository**: [URL]
- **Community Resources**: [URLs]
- **Tutorials**: [URLs]
- **Plugin/Extension Registry**: [URL]
- **Stack Overflow Tag**: [Tag name]

## Tool-Specific Guidelines

### Code Organization

- [How the tool affects code structure]
- [File organization recommendations]
- [Naming conventions]

### Maintenance

- [Regular maintenance tasks]
- [Update procedures]
- [Cleanup and optimization]

        return config_template

# === Enterprise Workflow Automation ===

class EnterpriseWorkflowManager:
"""Manage enterprise development workflows and automation"""

    def __init__(self, lint_engine: EnterpriseLintStagedEngine):
        self.lint_engine = lint_engine
        self.workflow_db = self._initialize_workflow_database()

    def setup_continuous_integration_workflow(self, repository: EnterpriseRepository) -> Dict[str, Any]:
        """Setup enterprise CI/CD workflow integration"""

        ci_config = {
            "repository_id": repository.repo_id,
            "workflow_type": "continuous_integration",
            "setup_timestamp": datetime.now().isoformat(),
            "pipeline_stages": [],
            "quality_gates": [],
            "security_checkpoints": [],
            "compliance_validations": []
        }

        # Pre-commit stage
        pre_commit_stage = {
            "stage_name": "pre_commit_validation",
            "triggers": ["git_pre_commit_hook"],
            "actions": [
                "lint_staged_security_scan",
                "code_quality_validation",
                "compliance_check",
                "performance_analysis"
            ],
            "failure_actions": ["block_commit", "notify_developer", "generate_report"],
            "success_actions": ["allow_commit", "update_metrics"]
        }
        ci_config["pipeline_stages"].append(pre_commit_stage)

        # Pre-push stage
        pre_push_stage = {
            "stage_name": "pre_push_validation",
            "triggers": ["git_pre_push_hook"],
            "actions": [
                "comprehensive_security_scan",
                "dependency_vulnerability_check",
                "integration_test_validation",
                "compliance_audit"
            ],
            "failure_actions": ["block_push", "notify_team", "create_ticket"],
            "success_actions": ["allow_push", "update_dashboard"]
        }
        ci_config["pipeline_stages"].append(pre_push_stage)

        # Quality gates
        ci_config["quality_gates"] = [
            {
                "gate_name": "security_gate",
                "threshold_criteria": {
                    "security_score": 8.0,
                    "critical_vulnerabilities": 0,
                    "secrets_detected": 0
                },
                "enforcement": "blocking"
            },
            {
                "gate_name": "quality_gate",
                "threshold_criteria": {
                    "code_coverage": 80.0,
                    "quality_score": 7.5,
                    "technical_debt": "acceptable"
                },
                "enforcement": "warning"
            },
            {
                "gate_name": "compliance_gate",
                "threshold_criteria": {
                    "compliance_score": 9.0,
                    "policy_violations": 0
                },
                "enforcement": "blocking"
            }
        ]

        return ci_config

    def generate_enterprise_dashboard_config(self, repository: EnterpriseRepository) -> Dict[str, Any]:
        """Generate enterprise monitoring dashboard configuration"""

        dashboard_config = {
            "dashboard_id": f"lint_staged_enterprise_{repository.repo_id}",
            "dashboard_name": f"Enterprise Pre-commit Analytics - {repository.name}",
            "created_at": datetime.now().isoformat(),
            "widgets": [],
            "alerts": [],
            "reports": []
        }

        # Security metrics widget
        security_widget = {
            "widget_id": "security_metrics",
            "widget_type": "security_dashboard",
            "title": "Pre-commit Security Validation",
            "metrics": [
                "total_security_scans",
                "security_issues_detected",
                "critical_vulnerabilities_blocked",
                "secrets_prevented",
                "security_score_trend"
            ],
            "visualization": "multi_chart",
            "refresh_interval": 300,  # 5 minutes
            "alerts": ["critical_security_issue", "security_score_degradation"]
        }
        dashboard_config["widgets"].append(security_widget)

        # Quality metrics widget
        quality_widget = {
            "widget_id": "quality_metrics",
            "widget_type": "quality_dashboard",
            "title": "Code Quality Validation",
            "metrics": [
                "files_processed_daily",
                "average_quality_score",
                "quality_violations_trend",
                "code_coverage_impact",
                "technical_debt_prevented"
            ],
            "visualization": "trend_analysis",
            "refresh_interval": 600,  # 10 minutes
        }
        dashboard_config["widgets"].append(quality_widget)

        # Performance analytics widget
        performance_widget = {
            "widget_id": "performance_analytics",
            "widget_type": "performance_dashboard",
            "title": "Pre-commit Performance Analytics",
            "metrics": [
                "average_processing_time",
                "throughput_files_per_minute",
                "resource_utilization",
                "bottleneck_analysis",
                "efficiency_score"
            ],
            "visualization": "performance_charts",
            "refresh_interval": 300
        }
        dashboard_config["widgets"].append(performance_widget)

        # Compliance tracking widget
        compliance_widget = {
            "widget_id": "compliance_tracking",
            "widget_type": "compliance_dashboard",
            "title": "Enterprise Compliance Status",
            "metrics": [
                "compliance_framework_status",
                "policy_violation_trends",
                "audit_trail_completeness",
                "regulatory_adherence_score"
            ],
            "visualization": "compliance_matrix",
            "refresh_interval": 1800  # 30 minutes
        }
        dashboard_config["widgets"].append(compliance_widget)

        # Team productivity widget
        productivity_widget = {
            "widget_id": "team_productivity",
            "widget_type": "productivity_dashboard",
            "title": "Developer Productivity Analytics",
            "metrics": [
                "commits_processed",
                "time_saved_automation",
                "developer_satisfaction_score",
                "workflow_efficiency",
                "error_prevention_rate"
            ],
            "visualization": "productivity_insights",
            "refresh_interval": 1200  # 20 minutes
        }
        dashboard_config["widgets"].append(productivity_widget)

        return dashboard_config

# === Advanced Enterprise Features ===

class EnterpriseSecurityOrchestrator:
"""Advanced security orchestration for enterprise lint-staged operations"""

    def __init__(self):
        self.security_policies = self._load_security_policies()
        self.threat_intelligence = self._initialize_threat_intelligence()
        self.incident_response = self._initialize_incident_response()

    def orchestrate_security_validation(self, repository: EnterpriseRepository, files: List[str]) -> Dict[str, Any]:
        """Orchestrate comprehensive security validation with threat intelligence"""

        security_orchestration = {
            "orchestration_id": f"sec_orch_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            "repository_id": repository.repo_id,
            "files_count": len(files),
            "orchestration_start": datetime.now().isoformat(),
            "security_layers": [],
            "threat_intelligence": {},
            "risk_assessment": {},
            "mitigation_actions": []
        }

        try:
            # Layer 1: Static security analysis
            static_analysis = self._perform_static_security_analysis(files)
            security_orchestration["security_layers"].append({
                "layer_name": "static_analysis",
                "status": static_analysis["status"],
                "findings": static_analysis["findings"],
                "risk_score": static_analysis["risk_score"]
            })

            # Layer 2: Dynamic threat detection
            dynamic_analysis = self._perform_dynamic_threat_detection(files)
            security_orchestration["security_layers"].append({
                "layer_name": "dynamic_analysis",
                "status": dynamic_analysis["status"],
                "threats_detected": dynamic_analysis["threats"],
                "behavioral_anomalies": dynamic_analysis["anomalies"]
            })

            # Layer 3: Threat intelligence correlation
            threat_correlation = self._correlate_threat_intelligence(files)
            security_orchestration["threat_intelligence"] = threat_correlation

            # Layer 4: Risk assessment and scoring
            risk_assessment = self._perform_enterprise_risk_assessment(security_orchestration)
            security_orchestration["risk_assessment"] = risk_assessment

            # Layer 5: Automated mitigation
            if risk_assessment["overall_risk_score"] > 7.0:
                mitigation_actions = self._trigger_automated_mitigation(security_orchestration)
                security_orchestration["mitigation_actions"] = mitigation_actions

            security_orchestration["orchestration_end"] = datetime.now().isoformat()

        except Exception as e:
            logger.error(f"Security orchestration failed: {e}")
            security_orchestration["error"] = str(e)
            security_orchestration["status"] = "ERROR"

        return security_orchestration

# === Configuration Generation ===

def generate_enterprise_lint_staged_setup(repository_config: Dict[str, Any]) -> Dict[str, Any]:
"""Generate complete enterprise lint-staged setup"""

    setup_result = {
        "setup_id": f"enterprise_setup_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        "generated_at": datetime.now().isoformat(),
        "repository_config": repository_config,
        "generated_files": [],
        "configuration_templates": {},
        "integration_scripts": {},
        "monitoring_setup": {},
        "documentation": {}
    }

    # Create repository object
    repository = EnterpriseRepository(
        repo_id=repository_config.get("repo_id", "default"),
        name=repository_config.get("name", "Enterprise Repository"),
        path=Path(repository_config.get("path", ".")),
        security_level=repository_config.get("security_level", "high"),
        compliance_requirements=[
            ComplianceFramework(framework)
            for framework in repository_config.get("compliance_frameworks", ["OWASP"])
        ],
        file_types=repository_config.get("file_types", ["js", "ts", "py", "java"]),
        business_criticality=repository_config.get("business_criticality", "high"),
        team_size=repository_config.get("team_size", 10)
    )

    # Initialize enterprise engine
    lint_engine = EnterpriseLintStagedEngine()

    # Generate configurations
    config_generator = EnterpriseConfigurationGenerator()

    # 1. Main lint-staged configuration
    main_config = config_generator.generate_comprehensive_config(repository)
    setup_result["configuration_templates"]["lint_staged_config"] = main_config
    setup_result["generated_files"].append(".lintstagedrc.js")

    # 2. Package.json scripts integration
    package_json_scripts = {
        "scripts": {
            "lint-staged": "lint-staged",
            "lint-staged:security": "lint-staged --config .lintstagedrc.security.js",
            "lint-staged:compliance": "lint-staged --config .lintstagedrc.compliance.js",
            "pre-commit": "npm run lint-staged",
            "pre-push": "npm run lint-staged:security && npm run test:security",
            "security-audit": "npm run lint-staged:security && npm audit",
            "compliance-check": "npm run lint-staged:compliance"
        },
        "husky": {
            "hooks": {
                "pre-commit": "npm run pre-commit",
                "pre-push": "npm run pre-push"
            }
        },
        "lint-staged": {
            "*.{js,ts,jsx,tsx}": ["eslint --fix", "prettier --write"],
            "*.py": ["black", "isort", "flake8"],
            "*.{json,yaml,yml}": ["prettier --write"],
            "*.md": ["prettier --write", "markdownlint --fix"]
        }
    }
    setup_result["configuration_templates"]["package_json_integration"] = package_json_scripts

    # 3. Enterprise security configuration
    security_config = f'''

// Enterprise Security Configuration for Lint-staged
// High-security validation with comprehensive threat detection

export default {{
    // Critical security files - block commits
    '**/*.(env|key|pem|crt|cert|p12|pfx)': [
        () => {{ throw new Error('üö® SECURITY ALERT: Security-sensitive files detected'); }}
],

    // Source code with advanced security scanning
    '**/*.(js|ts|jsx|tsx|py|java|cs|php|rb|go|rs)': [
        'truffleHog --json --entropy=False git://.',
        'semgrep --config=security --json',
        'bandit -f json',
        (filenames) => {{
            // Custom security validation
            const securityPatterns = [
                /password\\s*=\\s*['"][^'"]+['"]/i,
                /api[_-]?key\\s*=\\s*['"][^'"]+['"]/i,
                /secret\\s*=\\s*['"][^'"]+['"]/i,
                /eval\\s*\\(/i,
                /innerHTML\\s*=.*\\+/i,
                /document\\.write\\s*\\(/i
            ];

            const violations = [];
            filenames.forEach(filename => {{
                const fs = require('fs');
                const content = fs.readFileSync(filename, 'utf8');

                securityPatterns.forEach((pattern, index) => {{
                    if (pattern.test(content)) {{
                        violations.push(`Security violation in ${{filename}}: Pattern ${{index + 1}}`);
                    }}
                }});
            }});

            if (violations.length > 0) {{
                throw new Error(`üö® SECURITY VIOLATIONS:\\n${{violations.join('\\n')}}`);
            }}

            return `‚úÖ Security validation passed for ${{filenames.length}} files`;
        }}
    ],

    // Dependency files with vulnerability scanning
    '**/package.json': [
        'npm audit --audit-level=moderate',
        'snyk test --severity-threshold=high'
    ],

    '**/requirements*.txt': [
        'safety check --json',
        'pip-audit --format=json'
    ],

    '**/Gemfile': [
        'bundle audit --update'
    ],

    '**/pom.xml': [
        'mvn org.owasp:dependency-check-maven:check'
    ]

}};
'''
setup_result["configuration_templates"]["security_config"] = security_config
setup_result["generated_files"].append(".lintstagedrc.security.js")

    # 4. Compliance configuration
    compliance_frameworks = [f.value for f in repository.compliance_requirements]
    compliance_config = f'''

// Enterprise Compliance Configuration for Lint-staged
// Compliance frameworks: {', '.join(compliance_frameworks)}

export default {{
// All source files with compliance validation
'\*_/_.(js|ts|jsx|tsx|py|java|cs|php|rb|go|rs)': [
(filenames) => {{
const complianceResults = [];
const complianceFrameworks = {compliance_frameworks};

            filenames.forEach(filename => {{
                const fs = require('fs');
                const content = fs.readFileSync(filename, 'utf8');

                // OWASP compliance checks
                if (complianceFrameworks.includes('OWASP')) {{
                    const owaspViolations = checkOWASPCompliance(content, filename);
                    if (owaspViolations.length > 0) {{
                        throw new Error(`OWASP compliance violations in ${{filename}}: ${{owaspViolations.join(', ')}}`);
                    }}
                }}

                // PCI-DSS compliance checks
                if (complianceFrameworks.includes('PCI-DSS')) {{
                    const pciViolations = checkPCIDSSCompliance(content, filename);
                    if (pciViolations.length > 0) {{
                        throw new Error(`PCI-DSS compliance violations in ${{filename}}: ${{pciViolations.join(', ')}}`);
                    }}
                }}

                // HIPAA compliance checks
                if (complianceFrameworks.includes('HIPAA')) {{
                    const hipaaViolations = checkHIPAACompliance(content, filename);
                    if (hipaaViolations.length > 0) {{
                        throw new Error(`HIPAA compliance violations in ${{filename}}: ${{hipaaViolations.join(', ')}}`);
                    }}
                }}
            }});

            return `‚úÖ Compliance validation passed for ${{filenames.length}} files`;
        }}
    ]

}};

// Compliance validation functions
function checkOWASPCompliance(content, filename) {{
const violations = [];

    // Check for hardcoded secrets
    if (/password\\s*=\\s*['"][^'"]+['"]/i.test(content)) {{
        violations.push('Hardcoded password detected');
    }}

    // Check for SQL injection patterns
    if (/SELECT\\s+.*\\s+WHERE\\s+.*=.*\\+/.test(content)) {{
        violations.push('Potential SQL injection vulnerability');
    }}

    return violations;

}}

function checkPCIDSSCompliance(content, filename) {{
const violations = [];

    // Check for credit card patterns
    if (/\\b4[0-9]{{12}}(?:[0-9]{{3}})?\\b/.test(content)) {{
        violations.push('Credit card number pattern detected');
    }}

    return violations;

}}

function checkHIPAACompliance(content, filename) {{
const violations = [];

    // Check for PHI patterns
    if (/\\b\\d{{3}}-\\d{{2}}-\\d{{4}}\\b/.test(content)) {{
        violations.push('SSN pattern detected');
    }}

    return violations;

}}
'''
setup_result["configuration_templates"]["compliance_config"] = compliance_config
setup_result["generated_files"].append(".lintstagedrc.compliance.js")

    # 5. Integration scripts
    setup_script = f'''#!/bin/bash

# Enterprise Lint-staged Setup Script

# Generated: {datetime.now().isoformat()}

set -e

echo "üöÄ Setting up Enterprise Lint-staged Configuration..."

# Check prerequisites

if ! command -v node &> /dev/null; then
echo "‚ùå Node.js is required but not installed"
exit 1
fi

if ! command -v npm &> /dev/null; then
echo "‚ùå npm is required but not installed"
exit 1
fi

echo "‚úÖ Prerequisites check passed"

# Install core dependencies

echo "üì¶ Installing core dependencies..."
npm install --save-dev lint-staged husky

# Install security tools

echo "üîí Installing security tools..."
npm install --save-dev eslint prettier
pip install truffleHog bandit safety semgrep

# Install quality tools

echo "üìä Installing quality tools..."  
npm install --save-dev @typescript-eslint/eslint-plugin @typescript-eslint/parser
pip install black isort flake8 mypy

# Setup Husky hooks

echo "ü™ù Setting up Git hooks..."
npx husky install
npx husky add .husky/pre-commit "npm run pre-commit"
npx husky add .husky/pre-push "npm run pre-push"

# Create configuration files

echo "‚öôÔ∏è Creating configuration files..."

# Main configuration

cat > .lintstagedrc.js << 'EOF'
{main_config}
EOF

# Security configuration

cat > .lintstagedrc.security.js << 'EOF'
{security_config}
EOF

# Compliance configuration

cat > .lintstagedrc.compliance.js << 'EOF'
{compliance_config}
EOF

# Create monitoring directory

mkdir -p .enterprise/monitoring
mkdir -p .enterprise/reports
mkdir -p .enterprise/logs

echo "‚úÖ Enterprise Lint-staged setup completed successfully!"
echo ""
echo "üìã Generated files:"
echo " - .lintstagedrc.js (Main configuration)"
echo " - .lintstagedrc.security.js (Security configuration)"  
echo " - .lintstagedrc.compliance.js (Compliance configuration)"
echo " - .husky/pre-commit (Pre-commit hook)"
echo " - .husky/pre-push (Pre-push hook)"
echo ""
echo "üîç Next steps:"
echo " 1. Review and customize configurations for your specific needs"
echo " 2. Test the setup with: git add . && git commit -m 'test'"
echo " 3. Monitor the .enterprise/logs/ directory for validation results"
echo " 4. Access enterprise dashboard at your monitoring URL"
'''
setup_result["integration_scripts"]["setup_script"] = setup_script
setup_result["generated_files"].append("setup-enterprise-lint-staged.sh")

    return setup_result

# === Documentation Generation ===

def generate_enterprise_documentation(repository: EnterpriseRepository) -> Dict[str, str]:
"""Generate comprehensive enterprise documentation"""

    documentation = {}

    # Main README
    documentation["README.md"] = f'''

# Enterprise Lint-staged Security & Quality Platform

## Overview

This repository is configured with enterprise-grade pre-commit validation using lint-staged with advanced security scanning, compliance validation, and quality assurance automation.

**Repository Information:**

- **Name**: {repository.name}
- **Security Level**: {repository.security_level.upper()}
- **Business Criticality**: {repository.business_criticality.upper()}
- **Team Size**: {repository.team_size} developers
- **Compliance Frameworks**: {', '.join([f.value for f in repository.compliance_requirements])}

## Enterprise Features

### üîí Security Validation

- **Secret Detection**: Prevents hardcoded credentials, API keys, and sensitive data
- **Vulnerability Scanning**: Automated dependency vulnerability detection
- **Code Injection Analysis**: Detects patterns that could lead to security vulnerabilities
- **Malware Scanning**: Advanced threat detection for suspicious file content
- **Threat Intelligence**: Real-time security intelligence integration

### üìä Quality Assurance

- **Code Quality Analysis**: Comprehensive linting, formatting, and complexity analysis
- **Documentation Validation**: Ensures adequate code documentation
- **Performance Analysis**: Identifies performance bottlenecks and inefficiencies
- **Test Coverage Validation**: Maintains quality through test coverage requirements
- **Style Consistency**: Enforces consistent code style across the entire codebase

### üìã Compliance Validation

- **Regulatory Compliance**: Automated validation for industry-specific regulations
- **Security Standards**: Adherence to security frameworks and best practices
- **Audit Trail Generation**: Comprehensive logging for compliance audits
- **Policy Enforcement**: Automated enforcement of organizational coding policies
- **Evidence Collection**: Systematic collection of compliance evidence

## Quick Start

### Prerequisites

- Node.js 18+
- Python 3.8+ (for security tools)
- Git hooks enabled

### Installation

```bash
# Run the enterprise setup script
chmod +x setup-enterprise-lint-staged.sh
./setup-enterprise-lint-staged.sh
```

### Usage

The system automatically runs on every commit. No manual intervention required.

```bash
# Normal development workflow
git add .
git commit -m "Your commit message"
# ‚Üë Enterprise validation runs automatically
```

## Configuration Files

### Main Configuration (`.lintstagedrc.js`)

Comprehensive validation for all file types with security, quality, and compliance checks.

### Security Configuration (`.lintstagedrc.security.js`)

High-security validation with threat detection and vulnerability scanning.

### Compliance Configuration (`.lintstagedrc.compliance.js`)

Regulatory compliance validation for {', '.join([f.value for f in repository.compliance_requirements])}.

## Monitoring and Analytics

### Enterprise Dashboard

Access your enterprise validation dashboard at your configured monitoring URL.

**Key Metrics:**

- Pre-commit validation success rate
- Security issues prevented
- Quality improvements over time
- Compliance status tracking
- Team productivity analytics

### Reports

- **Daily Security Reports**: `.enterprise/reports/security-daily.json`
- **Quality Metrics**: `.enterprise/reports/quality-metrics.json`
- **Compliance Status**: `.enterprise/reports/compliance-status.json`
- **Performance Analytics**: `.enterprise/reports/performance-analytics.json`

## Troubleshooting

### Common Issues

**Validation Taking Too Long**

```bash
# Check performance configuration
cat .lintstagedrc.js | grep concurrent
```

**Security Validation Failures**

```bash
# Review security logs
cat .enterprise/logs/security-validation.log
```

**Compliance Violations**

```bash
# Check compliance report
cat .enterprise/reports/compliance-status.json
```

### Support

- **Internal Support**: Contact your DevSecOps team
- **Documentation**: See `.enterprise/docs/` directory
- **Logs**: Check `.enterprise/logs/` for detailed information

## Enterprise Integration

### CI/CD Integration

This configuration integrates with your enterprise CI/CD pipeline for comprehensive validation throughout the development lifecycle.

### Security Tools Integration

- **SAST**: Static Application Security Testing
- **SCA**: Software Composition Analysis
- **DAST**: Dynamic Application Security Testing
- **Container Security**: Docker image vulnerability scanning

### Monitoring Systems

- **Real-time Alerts**: Critical security issues trigger immediate alerts
- **Performance Monitoring**: Continuous monitoring of validation performance
- **Compliance Tracking**: Automated compliance status reporting
- **Analytics Dashboard**: Executive-level insights and metrics

---

**Generated**: {datetime.now().isoformat()}
**Version**: Enterprise v2.0
**Support**: enterprise-security@company.com
'''

    # Security documentation
    documentation["SECURITY.md"] = f'''

# Enterprise Security Configuration

## Security Architecture

The enterprise lint-staged security configuration provides multiple layers of security validation:

### Layer 1: Static Security Analysis

- Secret detection and prevention
- Hardcoded credential scanning
- API key and token detection
- Certificate and private key identification

### Layer 2: Dynamic Threat Detection

- Behavioral analysis of code patterns
- Injection vulnerability detection
- Malicious code pattern recognition
- Runtime security risk assessment

### Layer 3: Dependency Security

- Vulnerability database scanning
- License compliance validation
- Supply chain security analysis
- Outdated dependency detection

### Layer 4: Compliance Integration

- {', '.join([f.value for f in repository.compliance_requirements])} compliance validation
- Security policy enforcement
- Regulatory requirement adherence
- Audit trail generation

## Security Rules

### Critical Security Issues (Blocking)

- Hardcoded secrets or credentials
- Known vulnerability patterns
- Malware signatures
- Security-sensitive file commits
- High-risk dependency vulnerabilities

### High-Risk Security Issues (Warning + Review)

- Potential injection vulnerabilities
- Insecure coding patterns
- Weak cryptographic implementations
- Insufficient input validation
- Exposure of sensitive information

## Configuration Files

### Security-Specific Configuration

Location: `.lintstagedrc.security.js`

This configuration focuses exclusively on security validation with enhanced threat detection capabilities.

### Integration with Main Configuration

The main configuration (`.lintstagedrc.js`) includes security validation as part of comprehensive file processing.

## Security Monitoring

### Real-time Alerts

- Critical security issues trigger immediate notifications
- Security score degradation alerts
- New vulnerability discovery notifications
- Compliance violation alerts

### Security Metrics

- Security validation success rate
- Threats prevented per day/week/month
- Security score trends
- Mean time to security issue resolution

## Incident Response

### Automated Response

1. **Immediate**: Block commit/push for critical issues
2. **Alert**: Notify security team for high-risk issues
3. **Log**: Record all security events for audit
4. **Report**: Generate security incident reports

### Manual Response Process

1. **Investigation**: Security team reviews flagged issues
2. **Assessment**: Risk evaluation and impact analysis
3. **Remediation**: Coordinate fix with development team
4. **Validation**: Confirm remediation effectiveness
5. **Documentation**: Update security policies if needed

---

**Security Contact**: security-team@company.com
**Emergency Contact**: security-emergency@company.com
**Last Updated**: {datetime.now().isoformat()}
'''

    return documentation

## Core Lint-staged Configuration

The following sections provide comprehensive enterprise configuration templates and examples.

### Enhanced Enterprise Configuration Templates

#### Basic Enterprise Setup

```javascript
// .lintstagedrc.js - Enterprise Basic Configuration
export default {
  // JavaScript/TypeScript with security validation
  '**/*.(js|ts|jsx|tsx)': [
    'eslint --fix --max-warnings=0',
    'prettier --write',
    (filenames) => {
      // Custom security validation
      const fs = require('fs');
      const securityIssues = [];

      filenames.forEach((filename) => {
        const content = fs.readFileSync(filename, 'utf8');

        // Check for hardcoded secrets
        if (/password\s*=\s*['"][^'"]+['"]/i.test(content)) {
          securityIssues.push(`Hardcoded password in ${filename}`);
        }

        // Check for API keys
        if (/api[_-]?key\s*=\s*['"][^'"]+['"]/i.test(content)) {
          securityIssues.push(`API key detected in ${filename}`);
        }
      });

      if (securityIssues.length > 0) {
        throw new Error(`üö® Security Issues:\n${securityIssues.join('\n')}`);
      }

      return `‚úÖ Security validation passed for ${filenames.length} files`;
    },
  ],

  // Python with comprehensive validation
  '**/*.py': [
    'black --line-length=120',
    'isort --profile black',
    'flake8 --max-line-length=120',
    'bandit -f json',
    'mypy --strict',
  ],

  // Configuration files
  '**/*.(json|yaml|yml)': [
    'prettier --write',
    (filenames) => {
      // Validate JSON/YAML structure
      filenames.forEach((filename) => {
        const fs = require('fs');
        const content = fs.readFileSync(filename, 'utf8');

        if (filename.endsWith('.json')) {
          try {
            JSON.parse(content);
          } catch (error) {
            throw new Error(`Invalid JSON in ${filename}: ${error.message}`);
          }
        }
      });

      return `‚úÖ Configuration files validated: ${filenames.length} files`;
    },
  ],

  // Security-sensitive files (blocking)
  '**/*.(env|key|pem|crt|cert)': [
    () => {
      throw new Error('üö® SECURITY ALERT: Security-sensitive files should not be committed');
    },
  ],
};
```

#### Advanced Security Configuration

```javascript
// .lintstagedrc.security.js - Advanced Security Configuration
import { execSync } from 'child_process';
import { readFileSync, existsSync } from 'fs';

// Advanced security validation functions
const securityValidation = {
  // Multi-layered secret detection
  async detectSecrets(filenames) {
    const results = [];

    // Layer 1: TruffleHog entropy detection
    try {
      execSync('truffleHog --json --entropy=True git://. --since_commit HEAD~1');
      results.push('‚úÖ TruffleHog: No secrets detected');
    } catch (error) {
      throw new Error('üö® TruffleHog detected potential secrets');
    }

    // Layer 2: detect-secrets baseline
    try {
      execSync('detect-secrets scan --baseline .secrets.baseline');
      results.push('‚úÖ detect-secrets: Baseline validation passed');
    } catch (error) {
      throw new Error('üö® New secrets detected by detect-secrets');
    }

    // Layer 3: Custom pattern matching
    const customPatterns = [
      { pattern: /-----BEGIN [A-Z ]+-----/, name: 'Private Key' },
      { pattern: /aws_access_key_id\s*=\s*[A-Z0-9]+/i, name: 'AWS Access Key' },
      { pattern: /sk-[a-zA-Z0-9]{48}/, name: 'OpenAI API Key' },
      { pattern: /ghp_[A-Za-z0-9]{36}/, name: 'GitHub Personal Access Token' },
      { pattern: /xoxb-[0-9]+-[0-9]+-[A-Za-z0-9]+/, name: 'Slack Bot Token' },
    ];

    for (const filename of filenames) {
      if (existsSync(filename)) {
        const content = readFileSync(filename, 'utf8');

        for (const { pattern, name } of customPatterns) {
          if (pattern.test(content)) {
            throw new Error(`üö® SECURITY ALERT: ${name} detected in ${filename}`);
          }
        }
      }
    }

    results.push('‚úÖ Custom pattern validation passed');
    return results;
  },

  // Vulnerability scanning with multiple tools
  async scanVulnerabilities(filenames) {
    const results = [];

    // JavaScript/Node.js dependencies
    const packageFiles = filenames.filter((f) => f.includes('package.json'));
    if (packageFiles.length > 0) {
      try {
        execSync('npm audit --audit-level=moderate');
        execSync('snyk test --severity-threshold=high');
        results.push('‚úÖ Node.js dependencies: No high-risk vulnerabilities');
      } catch (error) {
        throw new Error('üö® High-risk vulnerabilities found in Node.js dependencies');
      }
    }

    // Python dependencies
    const pythonFiles = filenames.filter((f) => f.includes('requirements') || f.endsWith('.txt'));
    if (pythonFiles.length > 0) {
      try {
        execSync('safety check --json');
        execSync('pip-audit --format=json');
        results.push('‚úÖ Python dependencies: No known vulnerabilities');
      } catch (error) {
        throw new Error('üö® Vulnerabilities found in Python dependencies');
      }
    }

    return results;
  },

  // Advanced code pattern analysis
  async analyzeCodePatterns(filenames) {
    const results = [];
    const dangerousPatterns = [
      { pattern: /eval\s*\(/g, severity: 'CRITICAL', message: 'eval() usage detected' },
      {
        pattern: /innerHTML\s*=.*\+/g,
        severity: 'HIGH',
        message: 'Potential XSS via innerHTML concatenation',
      },
      {
        pattern: /document\.write\s*\(/g,
        severity: 'HIGH',
        message: 'document.write() usage detected',
      },
      { pattern: /exec\s*\(/g, severity: 'CRITICAL', message: 'exec() usage detected' },
      { pattern: /system\s*\(/g, severity: 'CRITICAL', message: 'system() call detected' },
      { pattern: /shell_exec\s*\(/g, severity: 'CRITICAL', message: 'shell_exec() usage detected' },
      {
        pattern: /SELECT\s+.*\s+WHERE\s+.*=.*\+/gi,
        severity: 'HIGH',
        message: 'Potential SQL injection',
      },
    ];

    const codeFiles = filenames.filter((f) => /\.(js|ts|jsx|tsx|py|php|java|cs|rb|go)$/.test(f));

    let criticalIssues = 0;
    let highIssues = 0;

    for (const filename of codeFiles) {
      if (existsSync(filename)) {
        const content = readFileSync(filename, 'utf8');

        for (const { pattern, severity, message } of dangerousPatterns) {
          const matches = content.match(pattern);
          if (matches) {
            if (severity === 'CRITICAL') {
              criticalIssues++;
              throw new Error(`üö® CRITICAL SECURITY ISSUE: ${message} in ${filename}`);
            } else if (severity === 'HIGH') {
              highIssues++;
              results.push(`‚ö†Ô∏è  HIGH RISK: ${message} in ${filename}`);
            }
          }
        }
      }
    }

    if (highIssues > 0) {
      results.push(`‚ö†Ô∏è  Found ${highIssues} high-risk security patterns`);
    } else {
      results.push('‚úÖ No dangerous code patterns detected');
    }

    return results;
  },
};

export default {
  // All source files with comprehensive security scanning
  '**/*.(js|ts|jsx|tsx|py|java|cs|php|rb|go|rs)': [
    async (filenames) => {
      console.log('üîí Starting comprehensive security validation...');

      // Multi-layer security validation
      await securityValidation.detectSecrets(filenames);
      await securityValidation.analyzeCodePatterns(filenames);

      console.log('‚úÖ Security validation completed successfully');
      return `‚úÖ Advanced security validation passed for ${filenames.length} files`;
    },
  ],

  // Package files with vulnerability scanning
  '**/package.json': [
    async (filenames) => {
      await securityValidation.scanVulnerabilities(filenames);
      return '‚úÖ Dependency vulnerability scan completed';
    },
  ],

  // Python requirements with security scanning
  '**/requirements*.txt': [
    async (filenames) => {
      await securityValidation.scanVulnerabilities(filenames);
      return '‚úÖ Python dependency security scan completed';
    },
  ],

  // Infrastructure files with security validation
  '**/*.(dockerfile|docker-compose.yml|k8s.yml|terraform.tf)': [
    (filenames) => {
      const securityIssues = [];

      filenames.forEach((filename) => {
        const content = readFileSync(filename, 'utf8');

        // Check for hardcoded secrets in infrastructure files
        if (/password\s*[=:]\s*['"][^'"]+['"]/i.test(content)) {
          securityIssues.push(`Hardcoded password in ${filename}`);
        }

        // Check for default credentials
        if (/admin.*admin|root.*root|password.*password/i.test(content)) {
          securityIssues.push(`Default credentials in ${filename}`);
        }

        // Check for insecure protocols
        if (/http:\/\/(?!localhost|127\.0\.0\.1)/i.test(content)) {
          securityIssues.push(`Insecure HTTP protocol in ${filename}`);
        }
      });

      if (securityIssues.length > 0) {
        throw new Error(`üö® Infrastructure Security Issues:\n${securityIssues.join('\n')}`);
      }

      return `‚úÖ Infrastructure security validation passed for ${filenames.length} files`;
    },
  ],
};
```

#### Enterprise Compliance Configuration

```javascript
// .lintstagedrc.compliance.js - Regulatory Compliance Configuration
import { readFileSync, existsSync } from 'fs';
import { execSync } from 'child_process';

// Compliance validation functions for different frameworks
const complianceValidation = {

    // OWASP Top 10 compliance validation
    validateOWASP(filenames) {
        const violations = [];

        filenames.forEach(filename => {
            if (existsSync(filename)) {
                const content = readFileSync(filename, 'utf8');

                // A01: Broken Access Control
                if (/\\.(authorize|permit)\\s*\\(\\s*\\)/.test(content)) {
                    violations.push(`${filename}: Potential broken access control`);
                }

                // A02: Cryptographic Failures
                if (/(MD5|SHA1)\\s*\\(/.test(content)) {
                    violations.push(`${filename}: Weak cryptographic algorithm`);
                }

                // A03: Injection
                if (/query\\s*\\+\\s*user|SELECT.*WHERE.*=.*\\+/.test(content)) {
                    violations.push(`${filename}: Potential injection vulnerability`);
                }

                // A06: Vulnerable and Outdated Components
                // This would be handled by dependency scanning

                // A09: Security Logging and Monitoring Failures
                if (!/log|audit|monitor/i.test(content) && filename.includes('auth')) {
                    violations.push(`${filename}: Missing security logging in authentication code`);
                }
            }
        });

        return violations;
    },

    // PCI DSS compliance validation
    validatePCIDSS(filenames) {
        const violations = [];

        filenames.forEach(filename => {
            if (existsSync(filename)) {
                const content = readFileSync(filename, 'utf8');

                // Requirement 3: Protect stored cardholder data
                const cardPatterns = [
                    /\\b4[0-9]{12}(?:[0-9]{3})?\\b/, // Visa
                    /\\b5[1-5][0-9]{14}\\b/,        // Mastercard
                    /\\b3[47][0-9]{13}\\b/,         // American Express
                    /\\b6(?:011|5[0-9]{2})[0-9]{12}\\b/ // Discover
                ];

                cardPatterns.forEach((pattern, index) => {
                    if (pattern.test(content)) {
                        violations.push(`${filename}: Credit card number pattern detected (Pattern ${index + 1})`);
                    }
                });

                // Requirement 4: Encrypt transmission of cardholder data
                if (/http:\\/\\/(?!localhost)/.test(content) && /payment|card|billing/.test(content)) {
                    violations.push(`${filename}: Insecure transmission in payment-related code`);
                }

                // Requirement 8: Identify and authenticate access
                if (/password\\s*=\\s*['"][^'"]+['"]/.test(content)) {
                    violations.push(`${filename}: Hardcoded password violates PCI DSS`);
                }
            }
        });

        return violations;
    },

    // HIPAA compliance validation
    validateHIPAA(filenames) {
        const violations = [];

        filenames.forEach(filename => {
            if (existsSync(filename)) {
                const content = readFileSync(filename, 'utf8');

                // Protected Health Information (PHI) patterns
                const phiPatterns = [
                    { pattern: /\\b\\d{3}-\\d{2}-\\d{4}\\b/, name: 'SSN' },
                    { pattern: /\\b[A-Z]{2}\\d{8}\\b/, name: 'Medical Record Number' },
                    { pattern: /\\b\\d{10}\\b.*(?:patient|medical)/, name: 'Patient Identifier' },
                    { pattern: /(?:diagnosis|condition).*[A-Z]\\d{2}\\.\\d+/, name: 'ICD Code' }
                ];

                phiPatterns.forEach(({ pattern, name }) => {
                    if (pattern.test(content)) {
                        violations.push(`${filename}: Potential ${name} in source code`);
                    }
                });

                // Administrative Safeguards
                if (/user|patient|medical/.test(content) && !/encrypt|hash|secure/.test(content)) {
                    violations.push(`${filename}: PHI-related code missing security controls`);
                }

                // Technical Safeguards
                if (/database|db/.test(content) && /patient|medical/.test(content) && !/encrypt/.test(content)) {
                    violations.push(`${filename}: Medical database access without encryption references`);
                }
            }
        });

        return violations;
    },

    // GDPR compliance validation
    validateGDPR(filenames) {
        const violations = [];

        filenames.forEach(filename => {
            if (existsSync(filename)) {
                const content = readFileSync(filename, 'utf8');

                // Personal data processing patterns
                if (/collect|store|process/.test(content) && /personal|user|customer/.test(content)) {
                    if (!/consent|legal.*basis|legitimate.*interest/.test(content)) {
                        violations.push(`${filename}: Personal data processing without legal basis documentation`);
                    }
                }

                // Data subject rights
                if (/delete|remove|purge/.test(content) && /user|customer/.test(content)) {
                    if (!/audit|log/.test(content)) {
                        violations.push(`${filename}: Data deletion without audit trail`);
                    }
                }

                // International transfers
                if (/transfer|export|send/.test(content) && /data|user|customer/.test(content)) {
                    if (!/adequacy|safeguards|consent/.test(content)) {
                        violations.push(`${filename}: International data transfer without GDPR safeguards`);
                    }
                }

                // Data minimization
                if (/SELECT \\*/.test(content) && /user|customer|personal/.test(content)) {
                    violations.push(`${filename}: Potential over-collection of personal data (SELECT *)`);
                }
            }
        });

        return violations;
    }
};

export default {
    // All source files with compliance validation
    '**/*.(js|ts|jsx|tsx|py|java|cs|php|rb|go)': [
        (filenames) => {
            console.log('üìã Starting compliance validation...');

            const complianceFrameworks = ['OWASP', 'PCI-DSS', 'HIPAA', 'GDPR']; // Configure as needed
            const allViolations = [];

            // Run compliance checks for each framework
            complianceFrameworks.forEach(framework => {
                let violations = [];

                switch (framework) {
                    case 'OWASP':
                        violations = complianceValidation.validateOWASP(filenames);
                        break;
                    case 'PCI-DSS':
                        violations = complianceValidation.validatePCIDSS(filenames);
                        break;
                    case 'HIPAA':
                        violations = complianceValidation.validateHIPAA(filenames);
                        break;
                    case 'GDPR':
                        violations = complianceValidation.validateGDPR(filenames);
                        break;
                }

                if (violations.length > 0) {
                    allViolations.push(`${framework} Violations:`);
                    allViolations.push(...violations.map(v => `  - ${v}`));
                }
            });

            if (allViolations.length > 0) {
                throw new Error(`üö® COMPLIANCE VIOLATIONS:\n${allViolations.join('\n')}`);
            }

            console.log(`‚úÖ Compliance validation passed for ${complianceFrameworks.join(', ')}`);
            return `‚úÖ Compliance validation passed for ${filenames.length} files`;
        }
    ],

    // Database migration files with enhanced compliance
    '**/*migration*.(js|sql|py)': [
        (filenames) => {
            const violations = [];

            filenames.forEach(filename => {
                const content = readFileSync(filename, 'utf8');

                // Check for proper data handling in migrations
                if (/DROP|DELETE|TRUNCATE/i.test(content)) {
                    if (!/BACKUP|ARCHIVE/.test(content)) {
                        violations.push(`${filename}: Data deletion without backup in migration`);
                    }
                }

                // Check for encryption of sensitive columns
                if (/ADD COLUMN.*(?:email|phone|ssn|card)/i.test(content)) {
                    if (!/ENCRYPT|AES_ENCRYPT/.test(content)) {
                        violations.push(`${filename}: Sensitive column added without encryption`);
                    }
                }
            });

            if (violations.length > 0) {
                throw new Error(`üö® Migration Compliance Issues:\n${violations.join('\n')}`);
            }

            return `‚úÖ Migration compliance validation passed for ${filenames.length} files`;
        }
    ],

    // Configuration files with compliance checks
    '**/*.(env|config|ini|conf)': [
        (filenames) => {
            // Configuration files should be validated but not committed if they contain secrets
            const issues = [];

            filenames.forEach(filename => {
                if (filename.includes('.env') || filename.includes('config')) {
                    issues.push(`${filename}: Configuration file should not be committed to version control`);
                }
            });

            if (issues.length > 0) {
                throw new Error(`üö® Configuration File Issues:\n${issues.join('\n')}`);
            }

            return `‚úÖ Configuration compliance validated`;
        }
    ]
};
```

### Advanced Template Files

#### Enterprise Package.json Integration

```json
{
  "name": "enterprise-project",
  "scripts": {
    "lint-staged": "lint-staged",
    "lint-staged:security": "lint-staged --config .lintstagedrc.security.js",
    "lint-staged:compliance": "lint-staged --config .lintstagedrc.compliance.js",
    "pre-commit": "npm run lint-staged && npm run test:unit",
    "pre-push": "npm run lint-staged:security && npm run test:integration",
    "security-audit": "npm run lint-staged:security && npm audit && snyk test",
    "compliance-check": "npm run lint-staged:compliance",
    "enterprise-validation": "npm run security-audit && npm run compliance-check"
  },
  "husky": {
    "hooks": {
      "pre-commit": "npm run pre-commit",
      "pre-push": "npm run pre-push",
      "commit-msg": "commitlint -E HUSKY_GIT_PARAMS"
    }
  },
  "lint-staged": {
    "*.{js,ts,jsx,tsx}": [
      "eslint --fix --max-warnings=0",
      "prettier --write",
      "jest --findRelatedTests --passWithNoTests"
    ],
    "*.py": [
      "black --line-length=120",
      "isort --profile black",
      "flake8 --max-line-length=120",
      "pytest --collect-only"
    ],
    "*.{json,yaml,yml}": ["prettier --write"],
    "*.md": ["prettier --write", "markdownlint --fix"]
  },
  "devDependencies": {
    "lint-staged": "^15.0.0",
    "husky": "^8.0.0",
    "eslint": "^8.0.0",
    "prettier": "^3.0.0",
    "jest": "^29.0.0",
    "commitlint": "^17.0.0",
    "@commitlint/config-conventional": "^17.0.0",
    "markdownlint-cli": "^0.35.0"
  }
}
```

## Enterprise AI Assistant Guidelines

When helping with Enterprise Lint-staged Pre-commit Security & Quality Validation Platform:

### 1. Security-First Approach

- **Always prioritize security validation** over performance optimization
- **Implement comprehensive secret detection** using multiple validation layers
- **Include vulnerability scanning** for all dependency management files
- **Validate code patterns** for injection vulnerabilities and security risks
- **Block commits** containing security-sensitive files (keys, certificates, etc.)
- **Integrate with enterprise security tools** (SAST, SCA, DAST) when available
- **Generate detailed security reports** with actionable remediation guidance

### 2. Compliance Integration

- **Identify regulatory requirements** based on industry and data sensitivity
- **Implement framework-specific validation** for OWASP, PCI-DSS, HIPAA, GDPR, SOX, ISO-27001
- **Generate compliance evidence** and audit trails automatically
- **Validate data handling patterns** according to regulatory requirements
- **Document compliance status** in enterprise dashboards and reports
- **Provide compliance violation remediation** with framework-specific guidance

### 3. Enterprise Configuration Management

- **Use environment-specific configurations** for different security levels
- **Implement parallel processing** for optimal performance with large codebases
- **Configure intelligent caching** to reduce validation time
- **Setup monitoring and alerting** for validation failures and security issues
- **Integrate with CI/CD pipelines** for comprehensive validation workflows
- **Provide executive dashboards** with security and compliance metrics

### 4. Quality Assurance Integration

- **Combine linting with security scanning** for comprehensive validation
- **Implement code complexity analysis** with security implications
- **Validate documentation requirements** for security-critical functions
- **Check test coverage** for security-related code paths
- **Enforce coding standards** with security considerations
- **Monitor technical debt** that could introduce security vulnerabilities

### 5. Performance Optimization

- **Use parallel processing** for large file sets while maintaining security thoroughness
- **Implement intelligent file filtering** to focus validation on changed/relevant files
- **Configure resource limits** to prevent validation from impacting developer productivity
- **Use caching strategies** for expensive security scans (with proper cache invalidation)
- **Monitor validation performance** and optimize based on team feedback
- **Balance security thoroughness** with developer workflow efficiency

### 6. Enterprise Integration Patterns

- **Connect with security orchestration platforms** (SOAR) for incident response
- **Integrate with vulnerability management systems** for centralized security tracking
- **Setup webhook notifications** for security teams on critical findings
- **Connect with compliance management platforms** for regulatory tracking
- **Integrate with developer productivity tools** for seamless workflow
- **Setup enterprise monitoring** with real-time dashboards and alerting

### 7. Incident Response Integration

- **Automatically block high-risk commits** and notify security teams
- **Generate security incident tickets** for critical vulnerabilities
- **Provide detailed forensic information** for security investigations
- **Track remediation progress** and validate fixes
- **Document lessons learned** and update security policies
- **Maintain audit trails** for compliance and security reviews

### 8. Code Generation Rules for Enterprise Lint-staged

#### Security Configuration Generation

- Generate configurations with **multiple security validation layers**
- Include **comprehensive secret detection patterns** for various credential types
- Implement **vulnerability scanning integration** for all package managers
- Add **code pattern analysis** for security vulnerability detection
- Configure **security-sensitive file blocking** with appropriate exceptions
- Setup **threat intelligence integration** when available

#### Compliance Configuration Generation

- Generate **framework-specific validation rules** based on regulatory requirements
- Include **data pattern detection** for sensitive information (PII, PHI, PCI data)
- Implement **audit trail generation** for all validation activities
- Add **policy enforcement rules** based on organizational security policies
- Configure **evidence collection** for compliance reporting and audits
- Setup **violation tracking** and remediation workflows

#### Performance Configuration Generation

- Configure **parallel processing** optimized for team size and infrastructure
- Implement **intelligent caching** with proper security considerations
- Setup **resource monitoring** and optimization recommendations
- Configure **timeout handling** for long-running security scans
- Implement **load balancing** for distributed validation environments
- Add **performance analytics** and optimization suggestions

#### Integration Configuration Generation

- Generate **CI/CD pipeline integration** configurations
- Setup **enterprise tool integrations** (SIEM, SOAR, vulnerability management)
- Configure **monitoring and alerting** for various stakeholder groups
- Implement **webhook integrations** for security and compliance notifications
- Setup **dashboard configurations** for executive and operational visibility
- Add **API integrations** for enterprise security and compliance platforms

### 9. Troubleshooting and Support Guidelines

#### Security Issues

- Provide **detailed security issue analysis** with risk assessment
- Offer **multiple remediation options** ranked by security effectiveness
- Include **false positive analysis** and configuration tuning guidance
- Document **security exceptions process** for legitimate security risks
- Provide **security training resources** for common vulnerability types

#### Performance Issues

- Analyze **validation bottlenecks** and provide optimization recommendations
- Suggest **configuration adjustments** based on team size and codebase characteristics
- Provide **resource scaling guidance** for enterprise environments
- Offer **incremental validation strategies** for large repositories
- Document **performance monitoring setup** and interpretation

#### Compliance Issues

- Explain **regulatory requirements** in accessible language
- Provide **compliance gap analysis** and remediation roadmaps
- Offer **framework-specific guidance** for different regulatory requirements
- Document **evidence collection processes** for audit preparation
- Provide **policy template examples** for common compliance scenarios

### 10. Best Practices for Enterprise Environments

#### Multi-Repository Management

- Provide **centralized configuration management** for consistent security policies
- Implement **configuration inheritance** for organization-wide standards
- Setup **policy versioning** and change management processes
- Configure **cross-repository reporting** and analytics
- Implement **shared security rule libraries** for reusable validation logic

#### Scalability Considerations

- Design configurations for **horizontal scaling** across large development teams
- Implement **resource optimization** for high-volume validation scenarios
- Configure **distributed processing** for enterprise-scale operations
- Setup **load balancing** and failover mechanisms
- Plan for **capacity management** and growth projections

#### Security Operations Integration

- Connect validation results with **Security Information and Event Management (SIEM)** systems
- Integrate with **Security Orchestration, Automation and Response (SOAR)** platforms
- Setup **threat intelligence feeds** for enhanced vulnerability detection
- Configure **incident response workflows** for critical security findings
- Implement **security metrics collection** for enterprise dashboards

---

**Enterprise Support Contact**: enterprise-security@company.com
**Documentation Repository**: .enterprise/docs/
**Training Resources**: .enterprise/training/
**Last Updated**: Current date will be automatically inserted
